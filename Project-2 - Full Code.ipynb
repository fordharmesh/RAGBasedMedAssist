{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# **Project 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Business Use Case**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Statement:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fast-paced environment of healthcare centers, healthcare professionals often face the challenge of quick and accurate diagnosis of patients while managing an ever-increasing volume of medical information. Ensuring that healthcare providers have access to the latest and most comprehensive medical knowledge is crucial for improving patient outcomes and reducing the time needed to make informed decisions.\n",
    "\n",
    "There are multiple challenges that these professionals encounter daily, a few being\n",
    "\n",
    "- Information Overload: Medical professionals need to go through vast amounts of data and research to make accurate diagnoses and treatment plans. This can be overwhelming and time-consuming.\n",
    "- Efficiency: For overall patient care and quality health outcomes, quick and accurate diagnosis is vital, especially in emergency situations.\n",
    "- Access to Trusted Knowledge: In the ever-evolving healthcare industry, providing access to reliable and up-to-date medical information from renowned manuals and research papers is essential for maintaining high standards of care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objective:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A renowned chain of hospitals has decided to leverage AI to build a state-of-the-art solution to help healthcare professionals overcome the aforementioned challenges. They have recruited you as an AI specialist and tasked you with building a RAG-based AI solution that leverages renowned medical manuals as its knowledge base. This AI system will act as a POC towards an end product that’ll assist healthcare professionals in making better, quicker, and more accurate diagnoses, ultimately leading to faster patient resolutions and enabling better patient outcomes by reducing errors in diagnosis, saving valuable time for information retrieval, and standardizing care practices across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Diagnostic Assistance**: \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
    "\n",
    "**2. Drug Information**: \"Can you provide the trade names of medications used for treating hypertension?\"\n",
    "\n",
    "**3. Treatment Plans**: \"What are the first-line options and alternatives for managing rheumatoid arthritis?\"\n",
    "\n",
    "**4. Specialty Knowledge**: \"What are the diagnostic steps for suspected endocrine disorders?\"\n",
    "\n",
    "**5. Critical Care Protocols**: \"What is the protocol for managing sepsis in a critical care unit?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How This Application Empowers Professionals and Elevates Healthcare Organizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Enhanced Diagnostic Accuracy:**\n",
    "Provides evidence-based insights for better diagnosis and treatment.\n",
    "\n",
    "- **Time Efficiency:**\n",
    "Instantly retrieves critical information, saving valuable time.\n",
    "\n",
    "- **Improved Patient Care:**\n",
    "Ensures informed decisions with up-to-date medical knowledge.\n",
    "\n",
    "- **Cost-Effective Operations:**\n",
    "Reduces redundant tests and consultation delays, lowering costs.\n",
    "\n",
    "- **Knowledge Empowerment:**\n",
    "Keeps doctors updated on the latest advancements.\n",
    "\n",
    "- **Competitive Edge for the Hospital:**\n",
    "Positions the hospital as a leader in healthcare innovation.\n",
    "\n",
    "This collaboration between St. Bernard’s Medical Center and InnoviTech Solutions highlights the transformative potential of AI in revolutionizing healthcare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Install and Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711989006
    }
   },
   "outputs": [],
   "source": [
    "# Install the Azure Machine Learning SDK and FAISS-related utilities\n",
    "%pip install azure-ai-ml\n",
    "%pip install -U 'azureml-rag[faiss,hugging_face]>=0.2.36'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Configure Azure Machine Learning Workspace**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get client for AzureML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711991055
    }
   },
   "outputs": [],
   "source": [
    "#Write you are code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711991292
    }
   },
   "outputs": [],
   "source": [
    "# Define workspace configuration (replace with your details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile workspace.json\n",
    "#Write you are code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize credentials for Azure authentication\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MLClient to connect with AzureML\n",
    "#Write you are code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1732711991980
    }
   },
   "outputs": [],
   "source": [
    "# Create an AzureML Workspace object\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Register the Reports Dataset as a Data Asset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1732711995591
    }
   },
   "outputs": [],
   "source": [
    "#Write you are code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Set Up Azure OpenAI Connection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cells under _either_ heading (OpenAI or HuggingFace) to use the respective embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Note:**\n",
    "\n",
    "When selecting an embedding model, ensure consistency between the embedding model used here and the one configured for your vectorstore retriever. Using mismatched models may result in dimension mismatches, leading to errors during vector retrieval. For example:\n",
    "\n",
    "- If you use the `text-embedding-ada-002` model from Azure OpenAI for embedding creation, ensure the same model is specified for the vectorstore retriever.\n",
    "- Similarly, if using a HuggingFace model like `all-mpnet-base-v2`, configure the vectorstore retriever with this model.\n",
    "\n",
    "Maintaining alignment between the embedding model and vectorstore retriever is crucial for the proper functioning of your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711996030
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# # Azure Open AI redentials and the id of the deployed chat model are stored as\n",
    "# # key value pairs in a json file\n",
    "\n",
    "# with open('___________', 'r') as az_creds:   #Fill the blank with json credentails file \n",
    "#     data = az_creds.read()\n",
    "\n",
    "# # Credentials to authenticate to the personalized Open AI model server\n",
    "# import json\n",
    "# creds = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1732711996289
    }
   },
   "outputs": [],
   "source": [
    "# from azureml.rag.utils.connections import get_connection_by_name_v2, create_connection_v2\n",
    "\n",
    "# # Define the connection name for Azure OpenAI\n",
    "# # aoai_connection_name = \"_________________\"\n",
    "\n",
    "# # If the connection doesn't exist, create a new one\n",
    "# target = creds[\"AZURE_OPENAI_ENDPOINT\"]  # Replace with your Azure OpenAI endpoint\n",
    "# key = creds[\"AZURE_OPENAI_KEY\"]          # Replace with your Azure OpenAI API key\n",
    "# api_version = creds[\"AZURE_OPENAI_APIVERSION\"]    # Replace with the appropriate API version\n",
    "\n",
    "# aoai_connection = create_connection_v2(\n",
    "#     workspace=ws,\n",
    "#     name=aoai_connection_name,\n",
    "#     category=\"AzureOpenAI\",\n",
    "#     target=target,\n",
    "#     auth_type=\"ApiKey\",\n",
    "#     credentials={\"key\": key},\n",
    "#     metadata={\"ApiType\": \"azure\", \"ApiVersion\": api_version},\n",
    "# )\n",
    "\n",
    "# aoai_connection_id = aoai_connection[\"id\"]\n",
    "\n",
    "# print(f\"Azure OpenAI connection created or retrieved successfully: {aoai_connection_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Azure OpenAI `text-embedding-ada-002` model for embedding generation, ensure the model has been deployed and is ready for inference. [Follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy the embedding model in your Azure OpenAI resource.\n",
    "\n",
    "Once deployed, obtain the credentials for the text-embedding-ada-002 model and save them in your `config.json` file. This is necessary for the following code to execute successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the `config.json` file includes the appropriate keys:\n",
    "\n",
    "- `AZURE_OPENAI_EMBEDDING_MODEL`: Name of the Azure OpenAI embedding model.\n",
    "- `AZURE_OPENAI_EMBEDING_DEPLOYMENT`: Deployment name for the embedding model.\n",
    "\n",
    "Finally we will combine the deployment and model information into a uri form which the AzureML embeddings components expect as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1732711996664
    }
   },
   "outputs": [],
   "source": [
    "# aoai_embedding_model_name = creds[\"AZURE_OPENAI_EMBEDDING_MODEL\"]\n",
    "# aoai_embedding_deployment_name = creds[\"AZURE_OPENAI_EMBEDING_DEPLOYMENT\"]\n",
    "# embeddings_model_uri = f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_embedding_model_name}\"\n",
    "# print(f\"Embedding Model URI: {embeddings_model_uri}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711996834
    }
   },
   "outputs": [],
   "source": [
    "embeddings_model_uri = \"hugging_face://model/sentence-transformers/_________\"   #Fill the blank with embedding model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Setup Pipeline to process data into Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define Pipeline Components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711997216
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Write you are code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build the AzureML Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1732711997589
    }
   },
   "outputs": [],
   "source": [
    "# Write you are code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.Submit the Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711997772
    }
   },
   "outputs": [],
   "source": [
    "# Define the asset name and data source glob pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711997947
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get the input data asset path from the workspace datastore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711998122
    }
   },
   "outputs": [],
   "source": [
    "# Create the pipeline job by calling the defined pipeline function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732711998286
    }
   },
   "outputs": [],
   "source": [
    "# Add properties for better indexing and artifact tracking in the AzureML UI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1732711999316
    }
   },
   "outputs": [],
   "source": [
    "# Submit the pipeline job for execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1732712010376
    }
   },
   "outputs": [],
   "source": [
    "# Stream the pipeline job logs for real-time monitoring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# **Information Retrieval and Response Generation Using LangChain-FAISS and Azure OpenAI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.Installing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732712134331
    }
   },
   "outputs": [],
   "source": [
    "# Install the required LangChain and HuggingFace libraries\n",
    "%pip install -U langchain-community\n",
    "%pip install -U langchain-huggingface\n",
    "%pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Setting Up Data Retrieval**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Downloading and Setting Up FAISS Index Assets**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1732712145211
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary utilities for artifact retrieval\n",
    "\n",
    "\n",
    "# Retrieve the path to the latest FAISS index asset from Azure ML\n",
    "\n",
    "\n",
    "# Download the FAISS index asset to a local directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Loading the FAISS Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the FAISS Index and Preparing the Retriever**\n",
    "\n",
    "We load the FAISS index from the downloaded files and connect it to an embedding model. This embedding model ensures that queries are converted into vector space to match the stored documents effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Note:**\n",
    "When loading the FAISS index and setting up the retriever, it is crucial to use the same embedding model that was used during the creation of the FAISS index. This ensures that the dimensionality of the embeddings produced by the query matches the dimensionality of the embeddings stored in the FAISS index.\n",
    "\n",
    "If a different embedding model is used between these two steps, a dimension mismatch will occur, leading to errors in retrieving relevant documents or performing similarity searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing FAISS index files\n",
    "index_folder_path = \"___________________\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Specify the embedding model used during FAISS index creation\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# # Specify the embedding model used during FAISS index creation\n",
    "# embedding_model = AzureOpenAIEmbeddings(\n",
    "#     model=creds[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "#     azure_endpoint= creds[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "#     api_key= creds[\"AZURE_OPENAI_KEY\"],\n",
    "#     openai_api_version=creds[\"AZURE_OPENAI_APIVERSION\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Load the FAISS index and associate it with the embedding model\n",
    "\n",
    "# The retriever is now ready to perform similarity searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Performing a Similarity Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1732712192191
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define a query to test the retriever\n",
    "\n",
    "\n",
    "# Retrieve the top 3 most relevant documents\n",
    "\n",
    "\n",
    "# Display the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## **5: Creating the System and User Prompt Templates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1732712195483
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Write you are code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## **6. Generating the Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732712206584
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Install the rquired packages\n",
    "#!pip install openai==1.55.3 tiktoken==0.6 session-info --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732712206811
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1732712207082
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load Azure OpenAI credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1732712207252
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732712210913
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "##Create a function called generate_rag_response which can perform\n",
    "\n",
    "    # Retrieve relevant document chunks\n",
    "\n",
    "\n",
    "    # Combine document chunks into a single context\n",
    "\n",
    "\n",
    "    # Compose the prompt\n",
    "\n",
    "\n",
    "    # Generate the response using Azure OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: What is the protocol for managing sepsis in a critical care unit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"__________________________________\"    # Enter the question to be answered by the system here \n",
    "generate_rag_response(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"__________________________________\"   # Enter the question to be answered by the system here \n",
    "generate_rag_response(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"__________________________________\"   # Enter the question to be answered by the system here \n",
    "generate_rag_response(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"__________________________________\"   # Enter the question to be answered by the system here \n",
    "generate_rag_response(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"__________________________________\"   # Enter the question to be answered by the system here \n",
    "generate_rag_response(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Ahead!"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
